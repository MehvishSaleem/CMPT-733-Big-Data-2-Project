{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CI (p,n):\n",
    "    p = p/100\n",
    "    sd = ((p*(1-p))/n)**0.5\n",
    "    return (3*sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Facebook Data/statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Toxicity_Rate'] = (df['Toxicity']/df['Total'])*100 # Toxicity rate = number of toxic comments/total number\n",
    "df['sd_toxicity'] = CI(df['Toxicity_Rate'],df['Total']) # Calculating the 95% confidence interval for toxicty rates\n",
    "df['sd_percentage'] = CI(df['Percentage'],df['Toxicity']) # Calculating the 95% confidence interval for toxicty types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the upper and lower bounds\n",
    "df['Lower_Percentage'] = df['Percentage'] - df['sd_percentage']\n",
    "df['Upper_Percentage'] = df['Percentage'] + df['sd_percentage']\n",
    "df['Lower_Toxicity_Percentage'] = df['Toxicity_Rate'] - df['sd_toxicity']\n",
    "df['Upper_Toxicity_Percentage'] = df['Toxicity_Rate'] + df['sd_toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sd_percentage','sd_toxicity'],axis=1) #dropping the columns containing the standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Type</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Total</th>\n",
       "      <th>Toxicity_Rate</th>\n",
       "      <th>Lower_Percentage</th>\n",
       "      <th>Upper_Percentage</th>\n",
       "      <th>Lower_Toxicity_Percentage</th>\n",
       "      <th>Upper_Toxicity_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>racist</td>\n",
       "      <td>2.548615</td>\n",
       "      <td>6788</td>\n",
       "      <td>116722</td>\n",
       "      <td>5.815527</td>\n",
       "      <td>2.542877</td>\n",
       "      <td>2.554354</td>\n",
       "      <td>5.813472</td>\n",
       "      <td>5.817583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>sexist</td>\n",
       "      <td>1.237478</td>\n",
       "      <td>6788</td>\n",
       "      <td>116722</td>\n",
       "      <td>5.815527</td>\n",
       "      <td>1.233452</td>\n",
       "      <td>1.241503</td>\n",
       "      <td>5.813472</td>\n",
       "      <td>5.817583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>homophobic</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>6788</td>\n",
       "      <td>116722</td>\n",
       "      <td>5.815527</td>\n",
       "      <td>0.145922</td>\n",
       "      <td>0.148715</td>\n",
       "      <td>5.813472</td>\n",
       "      <td>5.817583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>racist</td>\n",
       "      <td>9.880843</td>\n",
       "      <td>45654</td>\n",
       "      <td>253485</td>\n",
       "      <td>18.010533</td>\n",
       "      <td>9.876653</td>\n",
       "      <td>9.885033</td>\n",
       "      <td>18.008243</td>\n",
       "      <td>18.012823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2.486091</td>\n",
       "      <td>45654</td>\n",
       "      <td>253485</td>\n",
       "      <td>18.010533</td>\n",
       "      <td>2.483905</td>\n",
       "      <td>2.488277</td>\n",
       "      <td>18.008243</td>\n",
       "      <td>18.012823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>News</td>\n",
       "      <td>homophobic</td>\n",
       "      <td>0.584834</td>\n",
       "      <td>45654</td>\n",
       "      <td>253485</td>\n",
       "      <td>18.010533</td>\n",
       "      <td>0.583763</td>\n",
       "      <td>0.585904</td>\n",
       "      <td>18.008243</td>\n",
       "      <td>18.012823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>racist</td>\n",
       "      <td>2.137108</td>\n",
       "      <td>3603</td>\n",
       "      <td>72756</td>\n",
       "      <td>4.952169</td>\n",
       "      <td>2.129880</td>\n",
       "      <td>2.144336</td>\n",
       "      <td>4.949756</td>\n",
       "      <td>4.954582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>sexist</td>\n",
       "      <td>19.150708</td>\n",
       "      <td>3603</td>\n",
       "      <td>72756</td>\n",
       "      <td>4.952169</td>\n",
       "      <td>19.131042</td>\n",
       "      <td>19.170374</td>\n",
       "      <td>4.949756</td>\n",
       "      <td>4.954582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>homophobic</td>\n",
       "      <td>1.859561</td>\n",
       "      <td>3603</td>\n",
       "      <td>72756</td>\n",
       "      <td>4.952169</td>\n",
       "      <td>1.852810</td>\n",
       "      <td>1.866313</td>\n",
       "      <td>4.949756</td>\n",
       "      <td>4.954582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category        Type  Percentage  Toxicity   Total  Toxicity_Rate  \\\n",
       "0         Sports      racist    2.548615      6788  116722       5.815527   \n",
       "1         Sports      sexist    1.237478      6788  116722       5.815527   \n",
       "2         Sports  homophobic    0.147319      6788  116722       5.815527   \n",
       "3           News      racist    9.880843     45654  253485      18.010533   \n",
       "4           News      sexist    2.486091     45654  253485      18.010533   \n",
       "5           News  homophobic    0.584834     45654  253485      18.010533   \n",
       "6  Entertainment      racist    2.137108      3603   72756       4.952169   \n",
       "7  Entertainment      sexist   19.150708      3603   72756       4.952169   \n",
       "8  Entertainment  homophobic    1.859561      3603   72756       4.952169   \n",
       "\n",
       "   Lower_Percentage  Upper_Percentage  Lower_Toxicity_Percentage  \\\n",
       "0          2.542877          2.554354                   5.813472   \n",
       "1          1.233452          1.241503                   5.813472   \n",
       "2          0.145922          0.148715                   5.813472   \n",
       "3          9.876653          9.885033                  18.008243   \n",
       "4          2.483905          2.488277                  18.008243   \n",
       "5          0.583763          0.585904                  18.008243   \n",
       "6          2.129880          2.144336                   4.949756   \n",
       "7         19.131042         19.170374                   4.949756   \n",
       "8          1.852810          1.866313                   4.949756   \n",
       "\n",
       "   Upper_Toxicity_Percentage  \n",
       "0                   5.817583  \n",
       "1                   5.817583  \n",
       "2                   5.817583  \n",
       "3                  18.012823  \n",
       "4                  18.012823  \n",
       "5                  18.012823  \n",
       "6                   4.954582  \n",
       "7                   4.954582  \n",
       "8                   4.954582  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
