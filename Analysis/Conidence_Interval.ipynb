{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CI (p,n):\n",
    "    p = p/100\n",
    "    sd = ((p*(1-p))/n)**0.5\n",
    "    return (3*sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Facebook Data/statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Toxicity_Rate'] = (df['Toxicity']/df['Total'])*100 # Toxicity rate = number of toxic comments/total number\n",
    "df['sd_toxicity'] = CI(df['Toxicity_Rate'],df['Total']) # Calculating the 95% confidence interval for toxicty rates\n",
    "df['sd_percentage'] = CI(df['Percentage'],df['Toxicity']) # Calculating the 95% confidence interval for toxicty types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computing the upper and lower bounds\n",
    "df['Lower_Percentage'] = df['Percentage'] - df['sd_percentage']\n",
    "df['Upper_Percentage'] = df['Percentage'] + df['sd_percentage']\n",
    "df['Lower_Toxicity_Percentage'] = df['Toxicity_Rate'] - df['sd_toxicity']\n",
    "df['Upper_Toxicity_Percentage'] = df['Toxicity_Rate'] + df['sd_toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['sd_percentage','sd_toxicity'],axis=1) #dropping the columns containing the standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Type</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Total</th>\n",
       "      <th>Toxicity_Rate</th>\n",
       "      <th>Lower_Percentage</th>\n",
       "      <th>Upper_Percentage</th>\n",
       "      <th>Lower_Toxicity_Percentage</th>\n",
       "      <th>Upper_Toxicity_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>racist</td>\n",
       "      <td>2.994140</td>\n",
       "      <td>9385</td>\n",
       "      <td>190986</td>\n",
       "      <td>4.913973</td>\n",
       "      <td>2.988862</td>\n",
       "      <td>2.999417</td>\n",
       "      <td>4.912489</td>\n",
       "      <td>4.915457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>sexist</td>\n",
       "      <td>1.204049</td>\n",
       "      <td>9385</td>\n",
       "      <td>190986</td>\n",
       "      <td>4.913973</td>\n",
       "      <td>1.200672</td>\n",
       "      <td>1.207427</td>\n",
       "      <td>4.912489</td>\n",
       "      <td>4.915457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>homophobic</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>9385</td>\n",
       "      <td>190986</td>\n",
       "      <td>4.913973</td>\n",
       "      <td>0.211678</td>\n",
       "      <td>0.214534</td>\n",
       "      <td>4.912489</td>\n",
       "      <td>4.915457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>racist</td>\n",
       "      <td>7.109703</td>\n",
       "      <td>31886</td>\n",
       "      <td>193769</td>\n",
       "      <td>16.455677</td>\n",
       "      <td>7.105386</td>\n",
       "      <td>7.114021</td>\n",
       "      <td>16.453150</td>\n",
       "      <td>16.458204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>sexist</td>\n",
       "      <td>4.964561</td>\n",
       "      <td>31886</td>\n",
       "      <td>193769</td>\n",
       "      <td>16.455677</td>\n",
       "      <td>4.960912</td>\n",
       "      <td>4.968211</td>\n",
       "      <td>16.453150</td>\n",
       "      <td>16.458204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>News</td>\n",
       "      <td>homophobic</td>\n",
       "      <td>0.762090</td>\n",
       "      <td>31886</td>\n",
       "      <td>193769</td>\n",
       "      <td>16.455677</td>\n",
       "      <td>0.760629</td>\n",
       "      <td>0.763551</td>\n",
       "      <td>16.453150</td>\n",
       "      <td>16.458204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>racist</td>\n",
       "      <td>2.868026</td>\n",
       "      <td>8926</td>\n",
       "      <td>189452</td>\n",
       "      <td>4.711484</td>\n",
       "      <td>2.862726</td>\n",
       "      <td>2.873326</td>\n",
       "      <td>4.710023</td>\n",
       "      <td>4.712944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>sexist</td>\n",
       "      <td>11.360072</td>\n",
       "      <td>8926</td>\n",
       "      <td>189452</td>\n",
       "      <td>4.711484</td>\n",
       "      <td>11.349995</td>\n",
       "      <td>11.370148</td>\n",
       "      <td>4.710023</td>\n",
       "      <td>4.712944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>homophobic</td>\n",
       "      <td>1.310778</td>\n",
       "      <td>8926</td>\n",
       "      <td>189452</td>\n",
       "      <td>4.711484</td>\n",
       "      <td>1.307166</td>\n",
       "      <td>1.314389</td>\n",
       "      <td>4.710023</td>\n",
       "      <td>4.712944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category        Type  Percentage  Toxicity   Total  Toxicity_Rate  \\\n",
       "0         Sports      racist    2.994140      9385  190986       4.913973   \n",
       "1         Sports      sexist    1.204049      9385  190986       4.913973   \n",
       "2         Sports  homophobic    0.213106      9385  190986       4.913973   \n",
       "3           News      racist    7.109703     31886  193769      16.455677   \n",
       "4           News      sexist    4.964561     31886  193769      16.455677   \n",
       "5           News  homophobic    0.762090     31886  193769      16.455677   \n",
       "6  Entertainment      racist    2.868026      8926  189452       4.711484   \n",
       "7  Entertainment      sexist   11.360072      8926  189452       4.711484   \n",
       "8  Entertainment  homophobic    1.310778      8926  189452       4.711484   \n",
       "\n",
       "   Lower_Percentage  Upper_Percentage  Lower_Toxicity_Percentage  \\\n",
       "0          2.988862          2.999417                   4.912489   \n",
       "1          1.200672          1.207427                   4.912489   \n",
       "2          0.211678          0.214534                   4.912489   \n",
       "3          7.105386          7.114021                  16.453150   \n",
       "4          4.960912          4.968211                  16.453150   \n",
       "5          0.760629          0.763551                  16.453150   \n",
       "6          2.862726          2.873326                   4.710023   \n",
       "7         11.349995         11.370148                   4.710023   \n",
       "8          1.307166          1.314389                   4.710023   \n",
       "\n",
       "   Upper_Toxicity_Percentage  \n",
       "0                   4.915457  \n",
       "1                   4.915457  \n",
       "2                   4.915457  \n",
       "3                  16.458204  \n",
       "4                  16.458204  \n",
       "5                  16.458204  \n",
       "6                   4.712944  \n",
       "7                   4.712944  \n",
       "8                   4.712944  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Facebook Data/Confidence_Intervals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
