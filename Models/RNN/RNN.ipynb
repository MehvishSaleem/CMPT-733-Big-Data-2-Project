{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score , precision_recall_fscore_support,accuracy_score,confusion_matrix\n",
    "\n",
    "from keras.models import Model , load_model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_cleaning(comment):\n",
    "    comment = comment.strip(\"b'\").strip('b\"') \n",
    "    comment = re.sub(\"\\\\[\\\\[(.*?)\\\\]\\\\]\",\"\",comment)        # Removing GIFs and images from comments\n",
    "    comment = re.sub(r'\\\\x\\S+',\"\",comment)  \n",
    "    #   Replacing apostrophes\n",
    "    comment = re.sub(r\"'s\",' is',comment)                   \n",
    "    comment = re.sub(r\"'re\",' are',comment)\n",
    "    comment = re.sub(r\"'t\",' not',comment)\n",
    "    comment = re.sub(r\"'m\",' am',comment)\n",
    "    comment = re.sub(r\"'d\",' would',comment)\n",
    "    comment = re.sub(r\"'ll\",' will',comment)\n",
    "    comment = re.sub(r\"'ve\",' have',comment)\n",
    "    comment = re.sub(r'[0-9]',\"\",comment)                    # Removing numbers\n",
    "    comment = re.sub(r'http\\S+',\"\",comment)                  # Removing Url\n",
    "    comment = re.sub(r'[\\n]',\" \",comment) \n",
    "    return comment.strip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    embed_size = 128\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(GRU(50, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(3, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_pred(file_path,col_name):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data[data[col_name].notnull()]\n",
    "    data = data[col_name].apply(lambda x : text_cleaning(x))\n",
    "    list_sentences_data = data.values\n",
    "    list_tokenized_data = tokenizer.texts_to_sequences(list_sentences_data)\n",
    "    comments = sequence.pad_sequences(list_tokenized_data,maxlen=maxlen)\n",
    "    return comments,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_df(X_test,df):\n",
    "    y_test = model.predict([X_test], batch_size=1024, verbose=1)\n",
    "    y_test = y_test.round(2)\n",
    "    prediction = []\n",
    "    for i in (y_test):\n",
    "        prediction.append(np.argmax(i,axis=0))\n",
    "    df = pd.DataFrame(df)\n",
    "    df['prediction'] = prediction\n",
    "    df = df[df['comment_message'].apply(lambda x:x != \"\")]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000 # vocabulary size , # of unique words to be used.\n",
    "maxlen = 100         # maximum number of words to be used for each comment\n",
    "\n",
    "train = pd.read_csv(\"mergedDataSet.csv\",usecols=['comment_text','merged_rating'])\n",
    "train = train.sample(frac=1,random_state=42)\n",
    "# test = pd.read_csv(\"Test_Data.csv\")\n",
    "\n",
    "list_sentences_train = train['comment_text'].apply(lambda x: text_cleaning(x))\n",
    "list_sentences_train = list_sentences_train.fillna(\"None\").values\n",
    "\n",
    "list_classes = ['merged_rating']\n",
    "y = train[list_classes].values\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y = one_hot_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "# list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "# X_test = sequence.pad_sequences(list_tokenized_test,maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "[X_train, X_val, y_train, y_val] = train_test_split(X_t, y, train_size=0.75, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120460 samples, validate on 40154 samples\n",
      "Epoch 1/2\n",
      "120460/120460 [==============================] - 928s 8ms/step - loss: 0.1774 - acc: 0.9417 - val_loss: 0.1465 - val_acc: 0.9482\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.965943 \n",
      "\n",
      "Epoch 2/2\n",
      "120460/120460 [==============================] - 1030s 9ms/step - loss: 0.1265 - acc: 0.9539 - val_loss: 0.1490 - val_acc: 0.9479\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.964809 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206514af518>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = get_model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "model1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                 callbacks=[RocAuc], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('GRU-2Epochs-Cleaned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sports,sports_df = clean_pred('sports_data.csv','comment_message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199999/199999 [==============================] - 270s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "sports_pred = pred_df(sports,sports_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40154/40154 [==============================] - 59s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_val], batch_size=32, verbose=1)\n",
    "y_test = y_test.round(2)\n",
    "prediction = []\n",
    "for i in (y_test):\n",
    "    prediction.append(np.argmax(i,axis=0))\n",
    "y_pred = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in (y_val):\n",
    "    true.append(np.argmax(i,axis=0))\n",
    "y_true = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz = precision_recall_fscore_support(y_true,y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94146941914887883, 0.94807491159037705, 0.94390464803365037, None)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94807491159037705"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36007\n",
       "2     2198\n",
       "1     1949\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_series = pd.Series(y_true)\n",
    "y_true_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35555,   384,    68],\n",
       "       [  898,   727,   324],\n",
       "       [  193,   218,  1787]], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
