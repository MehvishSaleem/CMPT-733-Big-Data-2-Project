{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedLineDocument\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/mergedDataSet.csv' #The complete file\n",
    "df = pd.read_csv(filename).iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = open('stop_words.txt','r').read().split()\n",
    "def RemoveStopWords(row):\n",
    "    row = row.lower().split() # converting to lower case and splitting\n",
    "    str1 = ''\n",
    "    for item in row:\n",
    "        if item not in stop: #removing stop words\n",
    "            item = re.sub(r'[^\\w\\s]','',item) #removing punctutions\n",
    "            str1 += (item + ' ')\n",
    "    return str1\n",
    "target = df['merged_rating'].values #Saving the target variable as a numpy array\n",
    "df = df['comment_text'].apply(RemoveStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsFileName = 'Data/comments.csv'\n",
    "\n",
    "df.to_csv(commentsFileName,index=False) # Writing the comments to a CSV file to be read by TaggedLineDocument next\n",
    "documents = TaggedLineDocument(commentsFileName) # Tags each sentence (0,1,2,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelSize = 500 # Will represent each comment with a vector of size 500\n",
    "modelWindow = 8 \n",
    "model = Doc2Vec(documents, vector_size=modelSize, window=modelWindow, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a numpy array to keep the data and to be used by a machine learning model as the feature vector\n",
    "data = np.zeros((len(model.docvecs),len(model.docvecs[0])))\n",
    "for i in range(len(model.docvecs)):\n",
    "    data[i]=model.docvecs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(data, target)\n",
    "\n",
    "dfData = pd.DataFrame(data=X_res,dtype=float)\n",
    "dfData['label']=y_res\n",
    "dfData.to_csv('Data/FeaturizedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LET THE PYSPARK BEGIN!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "import ast\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F, types\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = types.StructType([\n",
    "#     types.StructField(\"features\", types.StringType(), True),\n",
    "#     types.StructField(\"label\", types.IntegerType(), True),\n",
    "\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Data/FeaturizedData.csv',header=True)\n",
    "column_names = df.schema.names[1:]\n",
    "\n",
    "df.schema\n",
    "df = df.select(*(F.col(c).cast(\"float\").alias(c) for c in column_names))\n",
    "df = df.withColumn(\"label\", df[\"label\"].cast(types.IntegerType()))\n",
    "# df.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assemb = VectorAssembler(inputCols=column_names, outputCol=\"Vecfeatures\")\n",
    "vec_assemb.transform(df)#.show().Vecfeatures\n",
    "\n",
    "(trainingData, testingData) = df.randomSplit([0.7, 0.3])\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"Vecfeatures\", numTrees=10)\n",
    "pipeline = Pipeline(stages=[vec_assemb, rf])\n",
    "ML_model = pipeline.fit(trainingData)\n",
    "predictions = ML_model.transform(testingData)\n",
    "\n",
    "#df.schema.names#[0]\n",
    "# def convertTolist(vec):\n",
    "#     return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.09411914136923\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)\n",
    "# predictions.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\").write.option(\"sep\", \",\").save(\"predictions\", format=\"csv\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = \"All of my edits are good. Cunts like you who revert good edits because you're too stupid to understand how to write well , and then revert other edits just because you've decided to bear a playground grudge, are the problem.  Maybe one day you'll realise the damage you did to a noble project.  201.215.187.159\"\n",
    "#sentence = \"fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck fuck\"\n",
    "sentence = \"you fucking asshole\"\n",
    "#sentence = \"sweet starwberry sweet starwberry sweet starwberry sweet starwberry sweet starwberry sweet starwberry sweet starwberry sweet starwberry sweet starwberry sweet starwberry\"\n",
    "test = model.infer_vector(RemoveStopWords(sentence)).reshape(1,modelSize)\n",
    "pandas_df = pd.DataFrame(test)\n",
    "pandas_df['label'] = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "sample_pred = ML_model.transform(spark_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       2.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_pred.select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
